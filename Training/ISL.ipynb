{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3612 images belonging to 26 classes.\n",
      "Found 3612 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = r'extra_train'\n",
    "test_path = r'extra_test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(train_batches)\n",
    "\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers with activation functions\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 15, 15, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                294976    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 416410 (1.59 MB)\n",
      "Trainable params: 416410 (1.59 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the Adam optimizer\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "362/362 [==============================] - 17s 45ms/step - loss: 0.4054 - accuracy: 0.9615 - val_loss: 1.7312 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 19s 53ms/step - loss: 4.1281e-05 - accuracy: 1.0000 - val_loss: 1.7874 - val_accuracy: 0.8104 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 16s 45ms/step - loss: 9.9385e-06 - accuracy: 1.0000 - val_loss: 1.8858 - val_accuracy: 0.8029 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to your data\n",
    "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop], validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 0.7484906911849976; accuracy of 89.99999761581421%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sneha Jain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# For getting next batch of testing imgs...\n",
    "imgs, labels = next(test_batches) \n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "\n",
    "#Once the model is fitted we save the model using model.save()  function.\n",
    "\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on a small set of test data--\n",
      "\n",
      "U   Y   W   W   X   A   Y   A   X   D   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels\n",
      "U   Y   W   W   X   A   Y   A   X   Z   "
     ]
    }
   ],
   "source": [
    "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions on a small set of test data--\")\n",
    "print(\"\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "\n",
    "plotImages(imgs)\n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)], end='   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(r\"model.h5\")\n",
    "\n",
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "ROI_top = 100\n",
    "ROI_bottom = 300\n",
    "ROI_right = 150\n",
    "ROI_left = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accum_avg(frame, accumulated_weight):\n",
    "\n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "\n",
    "    cv2.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def segment_hand(frame, threshold=25):\n",
    "    global background\n",
    "    \n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
    "\n",
    "    _, thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Fetching contours in the frame (These contours can be of hand or any other object in foreground)...\n",
    "    contours, hierarchy = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If the length of contours list = 0, it means we didn't get any contours...\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        # The largest external contour should be the hand \n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Returning the hand segment (max contour) and the thresholded image of the hand...\n",
    "        return (thresholded, hand_segment_max_cont)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "num_frames =0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # flipping the frame to prevent inverted image of captured frame...\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    # ROI from the frame\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "\n",
    "\n",
    "    if num_frames < 70:\n",
    "        \n",
    "        cal_accum_avg(gray_frame, accumulated_weight)\n",
    "        \n",
    "        cv2.putText(frame_copy, \"FETCHING BACKGROUND...PLEASE WAIT\",\n",
    "  (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "    \n",
    "    else: \n",
    "        # segmenting the hand region\n",
    "        hand = segment_hand(gray_frame)\n",
    "        \n",
    "        # Checking if we are able to detect the hand...\n",
    "        if hand is not None:\n",
    "            \n",
    "            thresholded, hand_segment = hand\n",
    "\n",
    "            # Drawing contours around hand segment\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right,\n",
    "      ROI_top)], -1, (255, 0, 0),1)\n",
    "            \n",
    "            cv2.imshow(\"Thesholded Hand Image\", thresholded)\n",
    "            \n",
    "            thresholded = cv2.resize(thresholded, (64, 64))\n",
    "            thresholded = cv2.cvtColor(thresholded,\n",
    " cv2.COLOR_GRAY2RGB)\n",
    "            thresholded = np.reshape(thresholded,\n",
    "(1,thresholded.shape[0],thresholded.shape[1],3))\n",
    "            \n",
    "            pred = model.predict(thresholded)\n",
    "            cv2.putText(frame_copy, word_dict[np.argmax(pred)],\n",
    "(170, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "    # Draw ROI on frame_copy\n",
    "    cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right,\n",
    "    ROI_bottom), (255,128,0), 3)\n",
    "\n",
    "    # incrementing the number of frames for tracking\n",
    "    num_frames += 1\n",
    "\n",
    "    # Display the frame with segmented hand\n",
    "    cv2.putText(frame_copy, \"Sign Recognition\",\n",
    "    (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "\n",
    "\n",
    "    # Close windows with Esc\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all the windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
